<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>Enhancing Single Image to 3D Generation</title>
  
  <!-- Google Fonts -->
  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro" rel="stylesheet">
  
  <!-- Bulma CSS -->
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bulma@0.9.4/css/bulma.min.css">
  
  <!-- Font Awesome -->
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/all.min.css">
  
  <!-- Academicons -->
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">

  <style>
    body {
      font-family: 'Noto Sans', sans-serif;
    }
    .title, .subtitle {
      font-family: 'Google Sans', sans-serif;
    }
    .publication-title { 
      color: #2c3e50; /* A deep, professional blue */
    }
    .publication-authors {
      margin: 1em 0;
    }
    .author-block {
      display: inline-block;
      margin: 0 0.5em;
    }
    .center-image { 
      display: block; 
      margin-left: auto; 
      margin-right: auto; 
    }
    .round { 
      border-radius: 12px;
      box-shadow: 0 4px 12px rgba(0,0,0,0.1);
    }
    .author-img { 
      border-radius: 50%; 
      width: 128px; 
      height: 128px; 
      object-fit: cover; 
    }
    .is-justified { 
      text-align: justify; 
    }
    .publication-links .button {
        transition: transform 0.2s ease-in-out;
    }
    .publication-links .button:hover {
        transform: translateY(-2px);
    }
    pre {
        white-space: pre-wrap;
        word-wrap: break-word;
        background-color: #f5f5f5;
        border-radius: 6px;
        padding: 16px;
    }
  </style>
</head>
<body>
  <!-- Hero Section -->
  <section class="hero">
    <div class="hero-body">
      <div class="container is-max-desktop">
        <div class="columns is-centered">
          <div class="column has-text-centered">
            <h1 class="title is-2 publication-title">Enhancing Single Image to 3D Generation using Gaussian Splatting and Hybrid Diffusion Priors</h1>
            <div class="is-size-5 publication-authors">
              <span class="author-block"><a href="#">Hritam Basak</a><sup>1,3</sup>,</span>
              <span class="author-block"><a href="#">Hadi Tabatabaeef</a><sup>â€ </sup>,</span>
              <span class="author-block"><a href="#">Shreekant Gayaka</a><sup>1</sup>,</span>
              <span class="author-block"><a href="#">Ming-Feng Li</a><sup>1,2</sup>,</span>
              <span class="author-block"><a href="#">Xin Yang</a><sup>1</sup>,</span>
              <span class="author-block"><a href="#">Cheng-Hao Kuo</a><sup>1</sup>,</span>
              <span class="author-block"><a href="#">Arnie Sen</a><sup>1</sup>,</span>
              <span class="author-block"><a href="#">Min Sun</a><sup>1</sup>,</span>
              <span class="author-block"><a href="#">Zhaozheng Yin</a><sup>3</sup></span>
            </div>
            <div class="is-size-5 publication-authors">
              <span class="author-block"><sup>1</sup>Amazon Lab126</span>
              <span class="author-block"><sup>2</sup>Carnegie Mellon University</span>
              <span class="author-block"><sup>3</sup>Stony Brook University</span>
            </div>
            <div class="is-size-5 column has-text-centered">
              <span>arXiv Preprint | 2024</span>
            </div>
            <div class="column has-text-centered">
              <div class="publication-links">
                <span class="link-block">
                  <a target="_blank" href="https://arxiv.org/abs/2410.09467" class="external-link button is-normal is-rounded is-dark">
                    <span class="icon"><i class="ai ai-arxiv"></i></span>
                    <span>Paper (arXiv)</span>
                  </a>
                </span>
                <span class="link-block">
                  <a target="_blank" href="#" class="external-link button is-normal is-rounded is-dark">
                    <span class="icon"><i class="fab fa-github-alt"></i></span>
                    <span>Code (Coming Soon)</span>
                  </a>
                </span>
              </div>
            </div>
          </div>
        </div>
      </div>
    </div>
  </section>

  <!-- Teaser/Overview -->
  <section class="hero teaser">
    <div class="container is-max-desktop">
      <div class="hero-body">
        <img class="round center-image" style="width:100%;" src="https://placehold.co/1200x500/e2e8f0/2c3e50?text=Single+Image+to+3D+Results" alt="Teaser Image showing single image to 3D generation results" />
        <h2 class="subtitle is-justified mt-5">
          <b>Overview:</b> Generating high-quality 3D objects from a single image is a major challenge. 2D diffusion models produce detailed textures but lack 3D consistency, while 3D models offer geometric consistency but often with blurry textures. We bridge this gap by introducing a novel two-stage, frequency-based distillation method. Our approach leverages geometric priors from a 3D diffusion model (low-frequency spectrum) and refines high-fidelity textures using a 2D diffusion model (high-frequency spectrum), resulting in geometrically consistent and visually detailed 3D assets.
        </h2>
      </div>
    </div>
  </section>

  <!-- Abstract -->
  <section class="section">
    <div class="container is-max-desktop">
      <div class="columns is-centered has-text-centered">
        <div class="column is-four-fifths">
          <h2 class="title is-3">Abstract</h2>
          <div class="content is-justified">
            <p>
              3D object generation from a single image involves estimating the full 3D geometry and texture of unseen views from an unposed RGB image captured in the wild. While recent methods use Gaussian Splatting guided by diffusion models, a disparity exists: 2D models create detailed visuals but lack cross-view consistency, whereas 3D models ensure consistency but often yield smooth textures. To address this, we propose bridging the gap by integrating a two-stage frequency-based distillation loss. We leverage low-frequency geometric priors from a 3D diffusion model for consistency and use a 2D diffusion model to refine high-frequency texture details. Our approach enhances both geometric consistency and visual quality, outperforming state-of-the-art methods and demonstrating adaptability for downstream robotics tasks like object pose estimation.
            </p>
          </div>
        </div>
      </div>
    </div>
  </section>

  <!-- Method -->
  <section class="section has-background-light">
    <div class="container is-max-desktop">
        <h2 class="title is-3 has-text-centered">Method</h2>
        <div class="hero-body">
            <img class="round center-image" style="width:90%;" src="https://placehold.co/1000x550/dbeafe/2c3e50?text=Overall+Workflow+Diagram" alt="Overall Workflow Diagram" />
        </div>
        <div class="columns is-centered">
            <div class="column is-four-fifths">
                <div class="content is-justified">
                    <p>
                      Our pipeline starts by generating multiple views from a single input image using a novel view synthesis (NVS) model (Zero123++). These views are then used to initialize a coarse 3D Gaussian Splatting representation via a Large Gaussian Model (LGM). The core of our method is the optimization of this representation using our proposed <b>Hybrid Frequency Score Distillation Loss (hf-SDL)</b>. This involves a sequential, two-stage process:
                      <br><b>1. Low-Frequency Guidance:</b> We use a 3D prior (Zero123) to distill geometric information from the low-frequency components of the rendered views, ensuring 3D consistency.
                      <br><b>2. High-Frequency Refinement:</b> We then use a 2D prior (Stable Diffusion) to distill textural details from the high-frequency components, adding sharpness and fidelity.
                      <br>This hybrid approach, combined with a reference view reconstruction loss, allows us to generate high-quality 3D assets in under a minute.
                    </p>
                </div>
            </div>
        </div>
    </div>
  </section>

  <!-- Results -->
  <section class="section">
    <div class="container is-max-desktop">
        <h2 class="title is-3 has-text-centered">Results</h2>
        <div class="columns is-centered">
            <div class="column is-four-fifths">
                <div class="content is-justified">
                    <p class="mb-5">
                      Our method demonstrates superior performance across multiple benchmarks, including GSO, Omni3D, and RealFusion15. We outperform existing state-of-the-art techniques in both 2D visual metrics (PSNR, SSIM, LPIPS) and 3D geometric metrics (Chamfer Distance, F-Score).
                    </p>
                    <img src="https://placehold.co/1000x400/e2e8f0/2c3e50?text=Quantitative+Comparison+Tables" alt="Quantitative Comparison Tables" class="round mb-5" />
                    <p>
                      <b>Qualitative Comparison:</b> As shown below, our generated models exhibit a higher degree of realism and fewer artifacts compared to other methods. While other approaches may produce distorted geometry or unrealistic shapes, our method maintains structural integrity and textural detail, highlighting the effectiveness of our hybrid frequency guidance.
                    </p>
                    <img src="https://placehold.co/1000x350/e2e8f0/2c3e50?text=Qualitative+Result+Comparisons" alt="Qualitative Result Comparisons" class="round" />
                </div>
            </div>
        </div>
    </div>
  </section>

  <!-- Ablation Study -->
  <section class="section has-background-light">
    <div class="container is-max-desktop">
        <h2 class="title is-3 has-text-centered">Ablation Study</h2>
        <div class="columns is-centered">
            <div class="column is-four-fifths">
                <div class="content is-justified">
                    <img src="https://placehold.co/1000x300/dbeafe/2c3e50?text=Ablation+Study+Visuals" alt="Ablation Study Visuals" class="round mb-5" />
                    <p>
                      We conducted ablation studies to validate the contribution of each component. Using only the 2D high-frequency prior ($L_{SDS}^{HF}$) results in good texture but poor geometry. Conversely, using only the 3D low-frequency prior ($L_{SDS}^{LF}$) produces geometrically accurate models that lack fine detail. The combination of both, along with our reference view guidance ($L_{R}$), yields the best performance, confirming that our hybrid approach is crucial for achieving both high-fidelity visuals and consistent geometry.
                    </p>
                </div>
            </div>
        </div>
    </div>
  </section>
  
  <!-- Authors -->
  <section class="section">
      <div class="container is-max-desktop">
          <h2 class="title is-3 has-text-centered">Authors</h2>
          <div class="columns is-centered is-multiline">
              <!-- Author 1 -->
              <div class="column is-narrow has-text-centered">
                  <img src="https://placehold.co/128x128/e2e8f0/2c3e50?text=HB" alt="Hritam Basak" class="author-img" />
                  <p><b>Hritam Basak</b></p>
              </div>
              <!-- Author 2 -->
              <div class="column is-narrow has-text-centered">
                  <img src="https://placehold.co/128x128/e2e8f0/2c3e50?text=HT" alt="Hadi Tabatabaeef" class="author-img" />
                  <p><b>Hadi Tabatabaeef</b></p>
              </div>
              <!-- Author 3 -->
              <div class="column is-narrow has-text-centered">
                  <img src="https://placehold.co/128x128/e2e8f0/2c3e50?text=SG" alt="Shreekant Gayaka" class="author-img" />
                  <p><b>Shreekant Gayaka</b></p>
              </div>
               <!-- Author 4 -->
              <div class="column is-narrow has-text-centered">
                  <img src="https://placehold.co/128x128/e2e8f0/2c3e50?text=ML" alt="Ming-Feng Li" class="author-img" />
                  <p><b>Ming-Feng Li</b></p>
              </div>
               <!-- Author 5 -->
              <div class="column is-narrow has-text-centered">
                  <img src="https://placehold.co/128x128/e2e8f0/2c3e50?text=ZY" alt="Zhaozheng Yin" class="author-img" />
                  <p><b>Zhaozheng Yin</b></p>
              </div>
          </div>
      </div>
  </section>

  <!-- BibTeX -->
  <section class="section" id="BibTeX">
    <div class="container is-max-desktop content">
      <h2 class="title">BibTeX</h2>
      <pre><code>@misc{basak2024enhancing,
    title={Enhancing Single Image to 3D Generation using Gaussian Splatting and Hybrid Diffusion Priors},
    author={Hritam Basak and Hadi Tabatabaeef and Shreekant Gayaka and Ming-Feng Li and Xin Yang and Cheng-Hao Kuo and Arnie Sen and Min Sun and Zhaozheng Yin},
    year={2024},
    eprint={2410.09467},
    archivePrefix={arXiv},
    primaryClass={cs.CV}
}</code></pre>
    </div>
  </section>

  <footer class="footer">
    <div class="content has-text-centered">
      <p>
        Website template based on the design from <a href="https://nerfies.github.io/">Nerfies</a>.
      </p>
    </div>
  </footer>
</body>
</html>
